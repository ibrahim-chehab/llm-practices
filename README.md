# Large Language Model (LLM) Practices

This repository contains a collection of practical exercises and applications using Large Language Models (LLMs). These practices explore the following topics:

## Contents
### 1. Introductory Notebooks
- **[finetuning-example.ipynb](./finetuning-example.ipynb)**: Fine-tune pre-trained language models on custom datasets.
- **[gpu_cpu_benchmark.ipynb](./gpu_cpu_benchmark.ipynb)**: Benchmark the performance of LLMs on GPU vs. CPU environments.
- **[intro_to_transformers_library.ipynb](./intro_to_transformers_library.ipynb)**: Introduction to the Transformers library by Hugging Face.

### 2. Applications
- **[1-simple-inference.py](./applications/1-simple-inference.py)**: Perform simple inference using a pre-trained LLM.
- **[2-gradio-chat.py](./applications/2-gradio-chat.py)**: Build an interactive chatbot using Gradio.
- **[3-rag-application-local.ipynb](./applications/3-rag-application-local.ipynb)**: Implement a Retrieval-Augmented Generation (RAG) application locally.

## Technologies
- Python
- Hugging Face Transformers Library
- Gradio
- GPU/CPU Benchmarks

## How to Use
1. Clone the repository: `git clone https://github.com/yourusername/LLM-Practices.git`
2. Install dependencies: `pip install -r requirements.txt`
3. Explore the notebooks and applications!

## Highlights
These practices showcase how to:
- Fine-tune LLMs on custom tasks.
- Benchmark model performance across hardware configurations.
- Develop practical applications such as chatbots and retrieval-augmented generation systems.
