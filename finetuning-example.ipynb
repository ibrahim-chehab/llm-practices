{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘AirlineTweets.csv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download data from provided link\n",
    "!wget -nc https://www.dropbox.com/s/lkd0eklmi64m9xm/AirlineTweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AirlineTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['airline_sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = { 'positive': 1, 'negative': 0, 'neutral': 2}\n",
    "df['target'] = df['airline_sentiment'].map(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['text','target']]\n",
    "df1.columns = ['sentence','label']\n",
    "df1.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./venv/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./venv/lib/python3.12/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.12/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./venv/lib/python3.12/site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larawehbe/Documents/Lara/Courses/LLMsCourse/Notebooks/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 14640 examples [00:00, 133214.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"csv\", data_files = 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 14640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = raw_dataset['train'].train_test_split(test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 10248\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 4392\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if we have multiple csv files\n",
    "# raw_dataset = load_dataset('csv', data_files = ['file1.csv','file2.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dataset = load_dataset('csv', \n",
    "#               data_files = { 'train': ['train1.csv','train2.csv'],\n",
    "#                              'test': 'test.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AutoTokenizer and create tokenizer object\n",
    "from transformers import AutoTokenizer\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokernizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "  return tokernizer(batch['sentence'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10248/10248 [00:00<00:00, 27572.26 examples/s]\n",
      "Map: 100%|██████████| 4392/4392 [00:00<00:00, 41167.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = split.map(tokenize_fn, batched = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a fine-tuning architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in ./venv/lib/python3.12/site-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "BertForSequenceClassification                                --\n",
       "├─BertModel: 1-1                                             --\n",
       "│    └─BertEmbeddings: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                   22,268,928\n",
       "│    │    └─Embedding: 3-2                                   393,216\n",
       "│    │    └─Embedding: 3-3                                   1,536\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─BertEncoder: 2-2                                      --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "│    └─BertPooler: 2-3                                       --\n",
       "│    │    └─Linear: 3-7                                      590,592\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─Linear: 1-3                                                2,307\n",
       "=====================================================================================\n",
       "Total params: 108,312,579\n",
       "Trainable params: 108,312,579\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larawehbe/Documents/Lara/Courses/LLMsCourse/Notebooks/venv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir='training_dir',\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  save_strategy='epoch',\n",
    "                                  num_train_epochs=3,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=64,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "  logits, labels = logits_and_labels\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  acc = np.mean(predictions == labels)\n",
    "  f1 = f1_score(labels, predictions, average = 'micro')\n",
    "  return {'accuracy': acc, 'f1_score': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qt/8nj7tb591mx9xtqkgz7mjyjh0000gn/T/ipykernel_6133/1048591017.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model,\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model,\n",
    "                  training_args,\n",
    "                  train_dataset = tokenized_dataset[\"train\"],\n",
    "                  eval_dataset = tokenized_dataset[\"test\"],\n",
    "                  tokenizer=tokernizer,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 39/1923 [02:33<2:03:14,  3.92s/it]\n",
      "  2%|▏         | 39/1923 [00:37<1:25:23,  2.72s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls training_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pipeline('text-classification',\n",
    "                       model = 'training_dir/checkpoint-1282')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = saved_model(split['test']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we are getting list of dictionaries. Next we will write a function to get labels only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(d):\n",
    "  return int(d['label'].split('_')[1])\n",
    "predictions = [get_label(d) for d in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"acc:\",accuracy_score(split['test']['label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1:\",f1_score(split['test']['label'], predictions, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for plotting confusion matrix\n",
    "def plot_cm(cm):\n",
    "  classes = ['negative','positive','neutral']\n",
    "  df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "  ax = sns.heatmap(df_cm, annot = True, fmt='g')\n",
    "  ax.set_xlabel('Predicted')\n",
    "  ax.set_ylabel('Actual')\n",
    "\n",
    "cm = confusion_matrix(split['test']['label'],predictions, normalize = 'true')\n",
    "plot_cm(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
